{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import check_call\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/1985-1987/ENCEN85.zip',\n",
       " 'data/1985-1987/ENCEN86.zip',\n",
       " 'data/1985-1987/ENCEN87.zip',\n",
       " 'data/1988-1990/ENCEN88.zip',\n",
       " 'data/1988-1990/ENCEN89.zip',\n",
       " 'data/1988-1990/ENCEN90.zip',\n",
       " 'data/1991-1993/ENCEN91.zip',\n",
       " 'data/1991-1993/ENCEN92.zip',\n",
       " 'data/1991-1993/ENCEN93.zip',\n",
       " 'data/1994-1996/ENCEN94.zip',\n",
       " 'data/1994-1996/ENCEN95.zip',\n",
       " 'data/1994-1996/ENCEN96.zip',\n",
       " 'data/1997-1999/ENCEN97.zip',\n",
       " 'data/1997-1999/ENCEN98.zip',\n",
       " 'data/1997-1999/ENCEN99.zip',\n",
       " 'data/2000-2002/ENCEN00.zip',\n",
       " 'data/2000-2002/ENCEN01.zip',\n",
       " 'data/2000-2002/ENCEN02.zip',\n",
       " 'data/2003-2005/ENCEN03.zip',\n",
       " 'data/2003-2005/ENCEN04.zip',\n",
       " 'data/2003-2005/ENCEN05.zip',\n",
       " 'data/2006-2008/ENCEN06.ZIP',\n",
       " 'data/2006-2008/ENCEN07.ZIP',\n",
       " 'data/2006-2008/ENCEN08.zip',\n",
       " 'data/2009-2011/ENCEN09.ZIP',\n",
       " 'data/2009-2011/ENCEN10.zip',\n",
       " 'data/2009-2011/ENCEN11.zip',\n",
       " 'data/2012-2015/ENCEN12.zip',\n",
       " 'data/2012-2015/ENCEN13.zip',\n",
       " 'data/2012-2015/ENCEN14.zip',\n",
       " 'data/2012-2015/ENCEN15.zip',\n",
       " 'data/1985-1987/WNCEN85.zip',\n",
       " 'data/1985-1987/WNCEN86.zip',\n",
       " 'data/1985-1987/WNCEN87.zip',\n",
       " 'data/1988-1990/WNCEN88.zip',\n",
       " 'data/1988-1990/WNCEN89.zip',\n",
       " 'data/1988-1990/WNCEN90.zip',\n",
       " 'data/1991-1993/WNCEN91.zip',\n",
       " 'data/1991-1993/WNCEN92.zip',\n",
       " 'data/1991-1993/WNCEN93.zip',\n",
       " 'data/1994-1996/WNCEN94.zip',\n",
       " 'data/1994-1996/WNCEN95.zip',\n",
       " 'data/1994-1996/WNCEN96.zip',\n",
       " 'data/1997-1999/WNCEN97.zip',\n",
       " 'data/1997-1999/WNCEN98.zip',\n",
       " 'data/1997-1999/WNCEN99.zip',\n",
       " 'data/2000-2002/WNCEN00.zip',\n",
       " 'data/2000-2002/WNCEN01.zip',\n",
       " 'data/2000-2002/WNCEN02.zip',\n",
       " 'data/2003-2005/WNCEN03.zip',\n",
       " 'data/2003-2005/WNCEN04.zip',\n",
       " 'data/2003-2005/WNCEN05.zip',\n",
       " 'data/2006-2008/WNCEN06.ZIP',\n",
       " 'data/2006-2008/WNCEN07.ZIP',\n",
       " 'data/2006-2008/WNCEN08.zip',\n",
       " 'data/2009-2011/WNCEN09.ZIP',\n",
       " 'data/2009-2011/WNCEN10.zip',\n",
       " 'data/2009-2011/WNCEN11.zip',\n",
       " 'data/2012-2015/WNCEN12.zip',\n",
       " 'data/2012-2015/WNCEN13.zip',\n",
       " 'data/2012-2015/WNCEN14.zip',\n",
       " 'data/2012-2015/WNCEN15.zip']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "dirs = sorted(glob('data/????-????'))\n",
    "\n",
    "regions = ['ENC', 'WNC']\n",
    "\n",
    "all_files = []\n",
    "for r in regions:\n",
    "    for d in dirs:\n",
    "        files_here = sorted(\n",
    "            glob(f'{d}/{r}*.zip') +     glob(f'{d}/{r}*.ZIP')\n",
    "        )\n",
    "        all_files.extend(files_here)\n",
    "all_files        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readline(line):\n",
    "    \"\"\"parse a single line of fertilizer data file\"\"\"\n",
    "    \n",
    "    column_defs = OrderedDict([\n",
    "        ('Fertilizer Year', dict(nchar=2, numeric=True, scale_factor=1)), \n",
    "        ('Extra county data', dict(nchar=1, numeric=False)),\n",
    "        ('State abbr', dict(nchar=2, numeric=False)),\n",
    "        ('County FIPS code', dict(nchar=3, numeric=True, scale_factor=1)),\n",
    "        ('Reporting period', dict(nchar=2, numeric=True, scale_factor=1)), \n",
    "        ('Quantity (tons)', dict(nchar=9, numeric=True, scale_factor=0.01)),\n",
    "        ('Fertilizer code', dict(nchar=3, numeric=True, scale_factor=1)),\n",
    "        ('Container', dict(nchar=1, numeric=True, scale_factor=1)), \n",
    "        ('Use', dict(nchar=1, numeric=True, scale_factor=1)), \n",
    "        ('Grade: N', dict(nchar=3, numeric=True, scale_factor=0.1)), \n",
    "        ('Grade: P', dict(nchar=3, numeric=True, scale_factor=0.1)),\n",
    "        ('Grade: K', dict(nchar=3, numeric=True, scale_factor=0.1)),\n",
    "    ])    \n",
    "    \n",
    "    ischar = ['Extra county data', 'State abbr']\n",
    "    \n",
    "    ndx0 = 0\n",
    "    data = {}\n",
    "    for name, info in column_defs.items():\n",
    "        n = info['nchar']\n",
    "        value = line[ndx0:ndx0+n]\n",
    "        if info['numeric']:\n",
    "            try:\n",
    "                value = int(value) * info['scale_factor']        \n",
    "            except:\n",
    "                value = np.nan       \n",
    "        data[name] = value\n",
    "        ndx0 += n\n",
    "    return data\n",
    "\n",
    "\n",
    "def file_to_df(file_in):\n",
    "    \"\"\"convert dumbass data format to dataframe\"\"\"\n",
    "    with open(file_in, 'r') as fid:\n",
    "        lines = fid.readlines()\n",
    "    lines = [l.strip() for l in lines]\n",
    "\n",
    "    df_lines = []        \n",
    "    for line in lines:\n",
    "        df_lines.append(readline(line))\n",
    "        \n",
    "    return pd.DataFrame(df_lines)\n",
    "\n",
    "\n",
    "def filter_df(df):\n",
    "    \"\"\"filter dataframe based on specified values; return dataframe including only matching rows\"\"\"\n",
    "    \n",
    "    filters = {\n",
    "        'Fertilizer code': [16, 20, 24, 25, 27, 29, 31, \n",
    "                            50, 64, 73, 77, 207, 263, 265, 267, \n",
    "                            443, 463, 613, 629, 649, 652, \n",
    "                            661, 663, 665, 667, 702, 714, 720, \n",
    "                            726, 728, 732, 734, 736, 744, 754,   \n",
    "                            770, 774, 780, 782, 783,],\n",
    "    }\n",
    "    \n",
    "    sel = np.ones(len(df)).astype(np.bool)\n",
    "    for key, values in filters.items():\n",
    "        sel = sel & df[key].isin(values)\n",
    "    return df.loc[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting: ENCEN85.R --> data/csv_output/ENCEN85.csv.gz\n",
      "converting: ENCEN86.R --> data/csv_output/ENCEN86.csv.gz\n",
      "converting: ENCEN87.R --> data/csv_output/ENCEN87.csv.gz\n",
      "converting: ENCEN88.R --> data/csv_output/ENCEN88.csv.gz\n",
      "converting: ENCEN89.R --> data/csv_output/ENCEN89.csv.gz\n",
      "converting: ENCEN90.R --> data/csv_output/ENCEN90.csv.gz\n",
      "converting: ENCEN91.R --> data/csv_output/ENCEN91.csv.gz\n",
      "converting: ENCEN92.R --> data/csv_output/ENCEN92.csv.gz\n",
      "converting: ENCEN93.R --> data/csv_output/ENCEN93.csv.gz\n",
      "converting: ENCEN94.R --> data/csv_output/ENCEN94.csv.gz\n",
      "converting: ENCEN95.R --> data/csv_output/ENCEN95.csv.gz\n",
      "converting: ENCEN96.R --> data/csv_output/ENCEN96.csv.gz\n",
      "converting: ENCEN97.R --> data/csv_output/ENCEN97.csv.gz\n",
      "converting: ENCEN98.R --> data/csv_output/ENCEN98.csv.gz\n",
      "converting: ENCEN99.R --> data/csv_output/ENCEN99.csv.gz\n",
      "converting: ENCEN00.R --> data/csv_output/ENCEN00.csv.gz\n",
      "converting: ENCEN01.R --> data/csv_output/ENCEN01.csv.gz\n",
      "converting: ENCEN02.R --> data/csv_output/ENCEN02.csv.gz\n",
      "converting: ENCEN03.R --> data/csv_output/ENCEN03.csv.gz\n",
      "converting: ENCEN04.R --> data/csv_output/ENCEN04.csv.gz\n",
      "converting: ENCEN05.R --> data/csv_output/ENCEN05.csv.gz\n",
      "converting: ENCEN06.ZIP --> data/csv_output/ENCEN06.ZIP\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ENCEN06.ZIP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f8a2978a794b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unzip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7fbd32bdf7e4>\u001b[0m in \u001b[0;36mfile_to_df\u001b[0;34m(file_in)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfile_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m\"\"\"convert dumbass data format to dataframe\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ENCEN06.ZIP'"
     ]
    }
   ],
   "source": [
    "diro = 'data/csv_output'\n",
    "os.makedirs(diro, exist_ok=True)\n",
    "\n",
    "dfs = []\n",
    "for this_file in all_files:\n",
    "    file_in = os.path.basename(this_file).replace('.zip', '.R')\n",
    "    file_out = f'{diro}/{file_in}'.replace('.R', '.csv.gz')\n",
    "    \n",
    "    print(f'converting: {file_in} --> {file_out}')\n",
    "    if not os.path.exists(file_in):\n",
    "        check_call(['unzip', this_file])\n",
    "    \n",
    "    df = file_to_df(file_in)\n",
    "    df = filter_df(df)    \n",
    "    df.to_csv(file_out, compression='gzip')\n",
    "    os.remove(file_in)\n",
    "    \n",
    "    dfs.append(df)\n",
    "    \n",
    "file_out = f'{diro}/{\"-\".join(regions)}-alldata.csv.gz'\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(file_out, compression='gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sfertilizer]",
   "language": "python",
   "name": "conda-env-sfertilizer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
